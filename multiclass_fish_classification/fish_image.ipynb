{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNet, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishClassifier:\n",
    "    def __init__(self, input_shape=(224, 224, 3), num_classes=None):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.models = {}\n",
    "        self.histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def setup_data_generators(self, train_dir, valid_dir, test_dir, batch_size=32):\n",
    "        \"\"\"Set up data generators with augmentation for training\"\"\"\n",
    "        # Training data generator with augmentation\n",
    "        self.train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        # Validation/Test data generator with only rescaling\n",
    "        self.valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        # Create generators\n",
    "        self.train_generator = self.train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=self.input_shape[:2],\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        self.valid_generator = self.valid_datagen.flow_from_directory(\n",
    "            valid_dir,\n",
    "            target_size=self.input_shape[:2],\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        self.test_generator = self.valid_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=self.input_shape[:2],\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        self.num_classes = len(self.train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def build_custom_cnn(self):\n",
    "        \"\"\"Build a custom CNN architecture\"\"\"\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        self.models['custom_cnn'] = model\n",
    "        return model\n",
    "    \n",
    "    def build_transfer_learning_model(self, base_model_name):\n",
    "        \"\"\"Build a transfer learning model using pre-trained architectures\"\"\"\n",
    "        base_models = {\n",
    "            'vgg16': VGG16,\n",
    "            'resnet50': ResNet50,\n",
    "            'mobilenet': MobileNet,\n",
    "            'inception': InceptionV3,\n",
    "            'efficientnet': EfficientNetB0\n",
    "        }\n",
    "        \n",
    "        # Get the base model\n",
    "        base_model = base_models[base_model_name](\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=self.input_shape\n",
    "        )\n",
    "        \n",
    "        # Freeze the base model layers\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Add custom layers\n",
    "        x = Flatten()(base_model.output)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(self.num_classes, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(base_model.input, outputs)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        self.models[base_model_name] = model\n",
    "        return model\n",
    "    \n",
    "    def train_model(self, model_name, epochs=20):\n",
    "        \"\"\"Train the specified model\"\"\"\n",
    "        model = self.models[model_name]\n",
    "        \n",
    "        # Set up callbacks\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            f'best_{model_name}.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True\n",
    "        )\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=[checkpoint, early_stopping]\n",
    "        )\n",
    "        \n",
    "        self.histories[model_name] = history\n",
    "        return history\n",
    "    \n",
    "    def evaluate_model(self, model_name):\n",
    "        \"\"\"Evaluate the model and return metrics\"\"\"\n",
    "        model = self.models[model_name]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(self.test_generator)\n",
    "        y_pred = np.argmax(predictions, axis=1)\n",
    "        y_true = self.test_generator.classes\n",
    "        \n",
    "        # Calculate metrics\n",
    "        report = classification_report(y_true, y_pred, target_names=self.test_generator.class_indices.keys())\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'history': self.histories[model_name].history\n",
    "        }\n",
    "    \n",
    "    def plot_training_history(self, model_name):\n",
    "        \"\"\"Plot training history for the specified model\"\"\"\n",
    "        history = self.histories[model_name].history\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'{model_name} - Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['loss'], label='Training Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'{model_name} - Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
